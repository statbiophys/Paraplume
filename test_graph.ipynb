{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gathenes/.pyenv/versions/3.10.13/envs/paratyping/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from typing import Dict, Tuple\n",
    "import torch\n",
    "import numpy as np\n",
    "from utils import format_pdb\n",
    "from torch.utils.data import Dataset\n",
    "import json\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "from torch_geometric.data import Data\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = torch.load(\"/home/gathenes/paragraph_benchmark/241026_expanded/test_set/embeddings.pt\", weights_only=True)\n",
    "with open(\"/home/gathenes/paragraph_benchmark/241026_expanded/test_set/dict.json\") as f :\n",
    "    dataset_dict = json.load(f)\n",
    "test_csv = pd.read_csv(\"/home/gathenes/paragraph_benchmark/expanded_dataset/test_set.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AminoAcidGraphEGNN(Dataset):\n",
    "    def __init__(self, dataset_dict: Dict, residue_embeddings: torch.Tensor, csv: pd.DataFrame, alpha: str = \"4.5\"):\n",
    "        self.dataset_dict = dataset_dict\n",
    "        self.residue_embeddings = residue_embeddings\n",
    "        self.alpha = alpha\n",
    "        self.csv = csv\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.residue_embeddings.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Load pdb code and chains\n",
    "        pdb = self.dataset_dict[str(index)][\"pdb_code\"]\n",
    "        pdb_path = f\"/home/gathenes/all_structures/imgt/{pdb}.pdb\"\n",
    "        heavy_chain = self.csv.query(\"pdb == @pdb\")[\"Hchain\"].values[0]\n",
    "        light_chain = self.csv.query(\"pdb == @pdb\")[\"Lchain\"].values[0]\n",
    "        chains = [heavy_chain, light_chain]\n",
    "\n",
    "        # Filter the PDB data\n",
    "        df_pdb = format_pdb(pdb_path).query(\"Atom_Name == 'CA' and Chain.isin(@chains)\")\n",
    "        df_pdb[\"IMGT\"] = df_pdb[\"Res_Num\"].str.replace(r'[a-zA-Z]$', '', regex=True).astype(int)\n",
    "        # Separate heavy and light chains\n",
    "        heavy_df = df_pdb.query(\"Chain == @heavy_chain\")\n",
    "        light_df = df_pdb.query(\"Chain == @light_chain\")\n",
    "        print(\"-\"*100)\n",
    "\n",
    "        heavy_res_dict = {res_num: idx for idx, res_num in enumerate(heavy_df[\"Res_Num\"])}\n",
    "        light_res_dict = {res_num: idx for idx, res_num in enumerate(light_df[\"Res_Num\"])}\n",
    "\n",
    "        cdrs = list(range(25, 40 + 1)) + list(range(54, 67 + 1)) + list(range(103, 119 + 1))\n",
    "\n",
    "        heavy_cdr = heavy_df.query(\"IMGT in @cdrs\")\n",
    "        print(heavy_cdr)\n",
    "        light_cdr = light_df.query(\"IMGT in @cdrs\")\n",
    "\n",
    "        # Prepare labels and embeddings\n",
    "        labels_heavy = torch.tensor(self.dataset_dict[str(index)][f\"H_id labels {self.alpha}\"], dtype=torch.float32)\n",
    "        labels_light = torch.tensor(self.dataset_dict[str(index)][f\"L_id labels {self.alpha}\"], dtype=torch.float32)\n",
    "        embedding = self.residue_embeddings[index]\n",
    "\n",
    "        # Collect features (feats) and coordinates (coors)\n",
    "        node_features = []\n",
    "        node_coords = []\n",
    "        node_labels = []\n",
    "        # Heavy chain features and coordinates\n",
    "        for i, res in enumerate(heavy_cdr[\"Res_Num\"].tolist()):\n",
    "            res_index = heavy_res_dict[res]\n",
    "            node_features.append(embedding[1 + res_index][2048:])  # Assuming embeddings are (num_nodes, 2048)\n",
    "            node_coords.append(heavy_cdr.iloc[i][[\"x\", \"y\", \"z\"]].astype(float).values)\n",
    "            node_labels.append(labels_heavy[res_index])\n",
    "\n",
    "        # Light chain features and coordinates\n",
    "        for i, res in enumerate(light_cdr[\"Res_Num\"].tolist()):\n",
    "            res_index = light_res_dict[res]\n",
    "            node_features.append(embedding[len(labels_heavy) + 2 + res_index][2048:])\n",
    "            node_coords.append(light_cdr.iloc[i][[\"x\", \"y\", \"z\"]].astype(float).values)\n",
    "            node_labels.append(labels_light[res_index])\n",
    "\n",
    "        # Convert features and coordinates to tensors and reshape as required\n",
    "        feats = torch.stack(node_features)  # Shape: (1, num_samples, num_feats)\n",
    "        labels = torch.stack(node_labels)\n",
    "        node_coords=np.array(node_coords)\n",
    "        coors = torch.tensor(node_coords, dtype=torch.float32)  # Shape: (1, num_samples, 3)\n",
    "\n",
    "        # Calculate pairwise distances for edges\n",
    "        antibody_coords = np.array(node_coords)\n",
    "        distances = np.linalg.norm(antibody_coords[:, np.newaxis] - antibody_coords, axis=2)\n",
    "\n",
    "        # Generate the edges tensor as specified\n",
    "        edges = torch.tensor(distances, dtype=torch.float32).unsqueeze(-1)  # Shape: (1, num_samples, num_samples, 1)\n",
    "\n",
    "        return (feats, coors, edges),labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = AminoAcidGraphEGNN(dataset_dict=dataset_dict, residue_embeddings=embeddings, csv=test_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graph_model import EGNN_Model\n",
    "from torch.utils.data import DataLoader\n",
    "model = EGNN_Model(num_feats = 480,graph_hidden_layer_output_dims = [480]*6,linear_hidden_layer_output_dims = [10]*2)\n",
    "dl=DataLoader(dataset, shuffle=True, batch_size=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "     Res_Num        x        y        z\n",
      "852        1  -25.073  -10.125   28.509\n",
      "861        2  -21.689   -8.487   29.109\n",
      "868        3  -19.617   -6.048   27.062\n",
      "877        4  -15.873   -5.450   27.060\n",
      "885        5  -14.336   -2.233   25.771\n",
      "...      ...      ...      ...      ...\n",
      "2514     224  -20.594   15.715   -0.402\n",
      "2523     225  -19.889   14.090   -3.768\n",
      "2531     226  -20.921   16.349   -6.664\n",
      "2538     227  -20.948   15.780  -10.477\n",
      "2545     228  -18.058   17.025  -12.625\n",
      "\n",
      "[223 rows x 4 columns]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "tensor([[ 0.0921,  0.1575,  0.1343,  ...,  0.4358,  0.1856, -0.2667],\n",
      "        [-0.1375,  0.2959, -0.0080,  ...,  0.2209, -0.5704, -0.3282],\n",
      "        [-0.0821,  0.0025,  0.1603,  ...,  0.0450, -0.3970,  0.2823],\n",
      "        ...,\n",
      "        [ 0.0764, -0.0536,  0.0724,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0618, -0.0478,  0.3522,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.0791, -0.1249,  0.2180,  ...,  0.0000,  0.0000,  0.0000]])\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "criterion =nn.BCELoss()\n",
    "for i,((feats, coors, edges),labels) in enumerate(dl):\n",
    "    if i==0:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1787613487.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[63], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    torch.nn as nn\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from torch_geometric.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "torch.nn as nn\n",
    "# Assuming 'dataset' is your graph dataset\n",
    "dataloader = DataLoader(dataset, batch_size=3, shuffle=True)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion =nn.BCELoss()\n",
    "\n",
    "def train(model, dataloader, optimizer, criterion, epochs=5):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for data in tqdm(dataloader):\n",
    "            data = data.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            out = model(data)\n",
    "            out = torch.sigmoid(out.squeeze(-1))\n",
    "            loss = criterion(out, data.y)  # Assuming `data.y` are node labels\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {total_loss / len(dataloader)}\")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "train(model, dataloader, optimizer, criterion)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ideas put aside"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "import networkx as nx\n",
    "\n",
    "class AminoAcidGraphSimple(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset_dict: Dict,\n",
    "        residue_embeddings: torch.Tensor,\n",
    "        csv: pd.DataFrame,\n",
    "        alpha: str = \"4.5\",\n",
    "    ):\n",
    "        self.dataset_dict = dataset_dict\n",
    "        self.residue_embeddings = residue_embeddings\n",
    "        self.alpha = alpha\n",
    "        self.csv = csv\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.residue_embeddings.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        pdb = self.dataset_dict[str(index)][\"pdb_code\"]\n",
    "        pdb_path = f\"/home/gathenes/all_structures/imgt/{pdb}.pdb\"\n",
    "        heavy_chain = self.csv.query(\"pdb == @pdb\")[\"Hchain\"].values[0]\n",
    "        light_chain = self.csv.query(\"pdb == @pdb\")[\"Lchain\"].values[0]\n",
    "        chains = [heavy_chain, light_chain]\n",
    "\n",
    "        # Filter the PDB data\n",
    "        df_pdb = format_pdb(pdb_path).query(\"Atom_Name == 'CA' and Chain.isin(@chains)\")\n",
    "        # Separate heavy and light chains\n",
    "        heavy_df = df_pdb.query(\"Chain == @heavy_chain\")\n",
    "        light_df = df_pdb.query(\"Chain == @light_chain\")\n",
    "        heavy_res_dict = {\n",
    "            res_num: idx for idx, res_num in enumerate(heavy_df[\"Res_Num\"])\n",
    "        }\n",
    "        light_res_dict = {\n",
    "            res_num: idx for idx, res_num in enumerate(light_df[\"Res_Num\"])\n",
    "        }\n",
    "\n",
    "        df_pdb = pd.concat([heavy_df, light_df])\n",
    "        df_pdb[\"IMGT\"] = (\n",
    "            df_pdb[\"Res_Num\"].str.replace(r\"[a-zA-Z]$\", \"\", regex=True).astype(int)\n",
    "        )\n",
    "        cdrs = (\n",
    "            list(range(25, 40 + 1))\n",
    "            + list(range(54, 67 + 1))\n",
    "            + list(range(103, 119 + 1))\n",
    "        )\n",
    "        df_pdb = df_pdb.query(\"IMGT in @cdrs\")\n",
    "\n",
    "        # Prepare labels and embeddings\n",
    "        labels_heavy = torch.tensor(\n",
    "            self.dataset_dict[str(index)][f\"H_id labels {self.alpha}\"],\n",
    "            dtype=torch.float32,\n",
    "        )\n",
    "        labels_light = torch.tensor(\n",
    "            self.dataset_dict[str(index)][f\"L_id labels {self.alpha}\"],\n",
    "            dtype=torch.float32,\n",
    "        )\n",
    "        embedding = self.residue_embeddings[index]\n",
    "\n",
    "        # Collect features and labels for the graph nodes\n",
    "        node_features = []\n",
    "        node_labels = []\n",
    "\n",
    "        # Heavy chain nodes\n",
    "        for i, res in enumerate(heavy_df[\"Res_Num\"].tolist()):\n",
    "            res_index = heavy_res_dict[res]\n",
    "            node_features.append(\n",
    "                embedding[1 + res_index][2048:]\n",
    "            )  # Assuming embeddings are (num_nodes, 2048)\n",
    "            node_labels.append(labels_heavy[res_index])\n",
    "\n",
    "        # Light chain nodes\n",
    "        for i, res in enumerate(light_df[\"Res_Num\"].tolist()):\n",
    "            res_index = light_res_dict[res]\n",
    "            node_features.append(embedding[len(labels_heavy) + 2 + res_index][2048:])\n",
    "            node_labels.append(labels_light[res_index])\n",
    "\n",
    "        # Convert features and labels to tensors\n",
    "        x = torch.stack(node_features)  # Shape: (num_nodes, 1024)\n",
    "        y = torch.stack(node_labels)  # Shape: (num_nodes, 3)\n",
    "\n",
    "        # Create edges based on 3D distances\n",
    "        antibody_coords = df_pdb[[\"x\", \"y\", \"z\"]].astype(float).values\n",
    "        distances = np.linalg.norm(\n",
    "            antibody_coords[:, np.newaxis] - antibody_coords, axis=2\n",
    "        )\n",
    "        antibody_indices, neighbor_indices = np.where(\n",
    "            (distances < 10) & (distances > 0)\n",
    "        )\n",
    "        edges = [(i, j) for i, j in zip(antibody_indices, neighbor_indices)]\n",
    "\n",
    "        # Prepare edge index for PyTorch Geometric\n",
    "        edge_index = (\n",
    "            torch.tensor(edges, dtype=torch.long).t().contiguous()\n",
    "        )  # Shape: (2, num_edges)\n",
    "\n",
    "        # Return graph data and labels\n",
    "        torch_graph = Data(x=x, edge_index=edge_index, y=y)\n",
    "        return torch_graph\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paratyping",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
