{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "from Levenshtein import distance\n",
    "from scipy.cluster.hierarchy import fcluster, linkage\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# making clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "mipe_train = pd.read_csv(\"/home/athenes/paratope_model/datasets/mipe/train_val.csv\")\n",
    "paragraph_train = pd.read_csv(\"/home/athenes/paratope_model/datasets/paragraph/train_set.csv\")\n",
    "pecan_train = pd.read_csv(\"/home/athenes/paratope_model/datasets/pecan/train_set.csv\")\n",
    "paragraph_val = pd.read_csv(\"/home/athenes/paratope_model/datasets/paragraph/val_set.csv\")\n",
    "pecan_val = pd.read_csv(\"/home/athenes/paratope_model/datasets/pecan/val_set.csv\")\n",
    "mipe_test = pd.read_csv(\"/home/athenes/paratope_model/datasets/mipe/test_set.csv\")\n",
    "paragraph_test = pd.read_csv(\"/home/athenes/paratope_model/datasets/paragraph/test_set.csv\")\n",
    "pecan_test = pd.read_csv(\"/home/athenes/paratope_model/datasets/pecan/test_set.csv\")\n",
    "\n",
    "concat_train = pd.concat([paragraph_train, pecan_train, mipe_train, paragraph_val, pecan_val, mipe_test, paragraph_test, pecan_test]).drop_duplicates(\"pdb\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "import pandas as pd\n",
    "from biopandas.pdb import PandasPdb\n",
    "\n",
    "def read_pdb_to_dataframe(\n",
    "    pdb_path: Optional[str] = None,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Read a PDB file, and return a Pandas DataFrame containing the atomic coordinates and metadata.\n",
    "\n",
    "    Args:\n",
    "        pdb_path (str, optional): Path to a local PDB file to read. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing the atomic coordinates and metadata, removed of it's\n",
    "        hydrogen atomswith one row per atom.\n",
    "    \"\"\"\n",
    "    atomic_df = PandasPdb().read_pdb(pdb_path).df[\"ATOM\"].query(\"element_symbol!='H'\")\n",
    "    atomic_df[\"IMGT\"]=atomic_df[\"residue_number\"].astype(str)+atomic_df[\"insertion\"].astype(str)\n",
    "    return atomic_df\n",
    "amino_acid_dict = {\n",
    "    \"ALA\": \"A\",\n",
    "    \"CYS\": \"C\",\n",
    "    \"ASP\": \"D\",\n",
    "    \"GLU\": \"E\",\n",
    "    \"PHE\": \"F\",\n",
    "    \"GLY\": \"G\",\n",
    "    \"HIS\": \"H\",\n",
    "    \"ILE\": \"I\",\n",
    "    \"LYS\": \"K\",\n",
    "    \"LEU\": \"L\",\n",
    "    \"MET\": \"M\",\n",
    "    \"ASN\": \"N\",\n",
    "    \"PRO\": \"P\",\n",
    "    \"GLN\": \"Q\",\n",
    "    \"ARG\": \"R\",\n",
    "    \"SER\": \"S\",\n",
    "    \"THR\": \"T\",\n",
    "    \"VAL\": \"V\",\n",
    "    \"TRP\": \"W\",\n",
    "    \"TYR\": \"Y\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1504 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1504/1504 [02:01<00:00, 12.40it/s]\n"
     ]
    }
   ],
   "source": [
    "records=[]\n",
    "for pdb,heavy,light in tqdm(concat_train[['pdb','Hchain','Lchain']].values):\n",
    "    if pdb in [\"4fqi\",\"4fqy\",\"3gbn\"]:\n",
    "        continue\n",
    "    hl_chains=[heavy,light]\n",
    "    if not Path(f\"/home/athenes/all_structures/imgt/{pdb}.pdb\").exists():\n",
    "        print(pdb)\n",
    "        continue\n",
    "    pdb_df = read_pdb_to_dataframe(f\"/home/athenes/all_structures/imgt/{pdb}.pdb\").query(\"chain_id in @hl_chains and atom_name=='CA'\")\n",
    "    triplets_heavy= pdb_df.query(\"chain_id==@heavy and residue_number<129\")[\"residue_name\"].tolist()\n",
    "    sequence_heavy = \"\".join([amino_acid_dict[each] for each in triplets_heavy])\n",
    "    triplets_light= pdb_df.query(\"chain_id==@light and residue_number<128\")[\"residue_name\"].tolist()\n",
    "    sequence_light = \"\".join([amino_acid_dict[each] for each in triplets_light])\n",
    "    records.append({\"pdb\":pdb,\"sequences\":sequence_heavy+sequence_light})\n",
    "df = pd.DataFrame.from_records(records)\n",
    "df.to_csv(\"/home/athenes/paratope_model/datasets/concats/sequences.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"/home/athenes/paratope_model/datasets/concats/sequences.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(subset=\"pdb\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1503\n"
     ]
    }
   ],
   "source": [
    "print(len(df))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# making train_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mipe_pdbs = set(mipe_test[\"pdb\"].unique())\n",
    "paragraph_pdbs = set(paragraph_test[\"pdb\"].unique())\n",
    "pecan_pdbs = set(pecan_test[\"pdb\"].unique())\n",
    "testset_pdbs=set.union(mipe_pdbs,pecan_pdbs,paragraph_pdbs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exclude_from_trainset(pdb_set):\n",
    "    exclude_train_pdbs = []\n",
    "    for pdb1, seq1 in tqdm(df[[\"pdb\",\"sequences\"]].values):\n",
    "        for pdb2, seq2 in df.query(\"pdb in @pdb_set\")[[\"pdb\",\"sequences\"]].values:\n",
    "            if distance(seq1, seq2) / (np.mean([len(seq1), len(seq2)]))<0.05:\n",
    "                exclude_train_pdbs.append(pdb1)\n",
    "    return list(set(exclude_train_pdbs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1503 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1503/1503 [00:02<00:00, 637.86it/s]\n",
      "100%|██████████| 1503/1503 [00:04<00:00, 348.27it/s]\n",
      "100%|██████████| 1503/1503 [00:03<00:00, 423.86it/s]\n"
     ]
    }
   ],
   "source": [
    "exclude_mipe = exclude_from_trainset(mipe_pdbs)\n",
    "exclude_paragraph = exclude_from_trainset(paragraph_pdbs)\n",
    "exclude_pecan = exclude_from_trainset(pecan_pdbs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_everything = set.union(set(exclude_paragraph), set(exclude_pecan), set(exclude_mipe))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "\n",
    "train_val_everything = concat_train.query(\"pdb not in @exclude_everything and pdb!='4fqi' and pdb!='4fqy' and pdb!='3gbn'\")\n",
    "test_everything = concat_train.query(\"pdb in @exclude_everything\")\n",
    "train_everything, val_everything = train_test_split(\n",
    "    train_val_everything,\n",
    "    test_size=0.25,  # 10% for validation\n",
    "    random_state=42  # For reproducibility\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "803\n"
     ]
    }
   ],
   "source": [
    "print(len(train_everything))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_everything.to_csv(\"/home/athenes/paratope_model/datasets/concats/train_set.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_everything.to_csv(\"/home/athenes/paratope_model/datasets/concats/val_set.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_everything.to_csv(\"/home/athenes/paratope_model/datasets/concats/test_set.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paratyping",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
