{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import (\n",
    "    average_precision_score,roc_auc_score\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "all=list(range(129))\n",
    "cdr1 = list(range(25, 40 + 1))\n",
    "cdr2=list(range(54, 67 + 1))\n",
    "cdr3=list(range(103, 119 + 1))\n",
    "cdrs = cdr1 + cdr2 + cdr3\n",
    "\n",
    "def get_f1_scores(predictions, column=\"prediction\", threshold1=0.5, threshold2=0.5):\n",
    "    # Filter predictions where IMGT_bis is in cdrs\n",
    "    cdr_predictions = predictions.query(\"IMGT_bis in @cdrs\")\n",
    "    non_cdr_predictions = predictions.query(\"IMGT_bis not in @cdrs\")\n",
    "\n",
    "    # Apply threshold1 to cdr_predictions\n",
    "    cdr_preds = (cdr_predictions[column] >= threshold1).astype(int).tolist()\n",
    "    cdr_labs = cdr_predictions[\"labels\"].tolist()\n",
    "\n",
    "    # Apply threshold2 to non_cdr_predictions\n",
    "    non_cdr_preds = (non_cdr_predictions[column] >= threshold2).astype(int).tolist()\n",
    "    non_cdr_labs = non_cdr_predictions[\"labels\"].tolist()\n",
    "\n",
    "    # Combine predictions and labels\n",
    "    all_preds = cdr_preds + non_cdr_preds\n",
    "    all_labs = cdr_labs + non_cdr_labs\n",
    "\n",
    "    # Calculate F1 score\n",
    "    f1 = f1_score(all_labs, all_preds)\n",
    "\n",
    "    return f1\n",
    "\n",
    "\n",
    "def get_mcc_scores(predictions, column=\"prediction\", threshold1=0.5,threshold2=0.5):\n",
    "    # Filter predictions where IMGT_bis is in cdrs\n",
    "    cdr_predictions = predictions.query(\"IMGT_bis in @cdrs\")\n",
    "    non_cdr_predictions = predictions.query(\"IMGT_bis not in @cdrs\")\n",
    "\n",
    "    # Apply threshold1 to cdr_predictions\n",
    "    cdr_preds = (cdr_predictions[column] >= threshold1).astype(int).tolist()\n",
    "    cdr_labs = cdr_predictions[\"labels\"].tolist()\n",
    "\n",
    "    # Apply threshold2 to non_cdr_predictions\n",
    "    non_cdr_preds = (non_cdr_predictions[column] >= threshold2).astype(int).tolist()\n",
    "    non_cdr_labs = non_cdr_predictions[\"labels\"].tolist()\n",
    "\n",
    "    # Combine predictions and labels\n",
    "    all_preds = cdr_preds + non_cdr_preds\n",
    "    all_labs = cdr_labs + non_cdr_labs\n",
    "    mcc = matthews_corrcoef(all_labs, all_preds)\n",
    "\n",
    "    return mcc\n",
    "def get_ap_scores(predictions, column=\"prediction\"):\n",
    "\n",
    "    preds = predictions[column].tolist()\n",
    "    labs = predictions[\"labels\"].tolist()\n",
    "    ap = average_precision_score(labs, preds)\n",
    "\n",
    "    return ap\n",
    "def get_roc_scores(predictions, column=\"prediction\"):\n",
    "    preds = predictions[column].tolist()\n",
    "    labs = predictions[\"labels\"].tolist()\n",
    "    roc = roc_auc_score(labs, preds)\n",
    "\n",
    "    return roc\n",
    "def get_ap_roc_f1_mcc_df(llm_path1,llm_path2, threshold=0.5, column=\"labels_llm2\"):\n",
    "    predictions_llm1 = pd.read_csv(llm_path1)\n",
    "    predictions_llm2 = pd.read_csv(llm_path2)\n",
    "    predictions_llm = pd.merge(predictions_llm1, predictions_llm2[['pdb', 'IMGT', 'chain_type', 'prediction', 'labels']],\n",
    "                        on=[\"pdb\", \"IMGT\", \"chain_type\"],\n",
    "                        how=\"left\",\n",
    "                        suffixes=(\"_llm1\", \"_llm2\"))\n",
    "    predictions_llm=predictions_llm.dropna()\n",
    "    predictions_llm[\"labels\"]=predictions_llm[\"labels_llm1\"]\n",
    "    predictions_llm[\"prediction\"]=predictions_llm[column]\n",
    "    predictions_llm[\"IMGT_bis\"] = predictions_llm[\"IMGT\"].str.replace(r'[a-zA-Z]$', '', regex=True).astype(int)\n",
    "\n",
    "    # Compute all metrics\n",
    "\n",
    "    f1_dict = {\n",
    "    }\n",
    "\n",
    "    mcc_dict = {\n",
    "    }\n",
    "    f1_llm_list = []\n",
    "    mcc_llm_list = []\n",
    "\n",
    "    for _, df_pdb in predictions_llm.groupby(\"pdb\"):\n",
    "\n",
    "        f1_llm_list.append(get_f1_scores(df_pdb, column=\"prediction\", threshold1=threshold, threshold2=threshold))\n",
    "        mcc_llm_list.append(get_mcc_scores(df_pdb, column=\"prediction\", threshold1=threshold, threshold2=threshold))\n",
    "\n",
    "    # Average the results across pdb groups\n",
    "\n",
    "\n",
    "    f1_dict[\"llm\"] = np.mean(f1_llm_list)\n",
    "    mcc_dict[\"llm\"] = np.mean(mcc_llm_list)\n",
    "    mcc_dict[\"metric\"]=\"mcc\"\n",
    "    f1_dict[\"metric\"]=\"f1\"\n",
    "\n",
    "\n",
    "    return f1_dict, mcc_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "paired_chain=pd.read_csv(\"/home/athenes/Paraplume/benchmark/paragraph/250526/lr-0.00005_dr-0.4,0.4,0.4_mk-0.4_bs-16_dim1-2000,1000,500_alphas-4,5,6_pen-0.00001_weight_1_emb_all_seed_1/prediction_test_set.csv\")\n",
    "heavy=pd.read_csv(\"/home/athenes/Paraplume/benchmark/paragraph/250526/lr-0.00005_dr-0.4,0.4,0.4_mk-0.4_bs-16_dim1-2000,1000,500_alphas-4,5,6_pen-0.00001_weight_1_emb_all_seed_1/prediction_test_set_heavy.csv\")\n",
    "light=pd.read_csv(\"/home/athenes/Paraplume/benchmark/paragraph/250526/lr-0.00005_dr-0.4,0.4,0.4_mk-0.4_bs-16_dim1-2000,1000,500_alphas-4,5,6_pen-0.00001_weight_1_emb_all_seed_1/prediction_test_set_light.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paired heavy\n",
      "f1 0.7236896925779821\n",
      "mcc 0.7005545517457616\n",
      "ap 0.7937420877877883\n",
      "roc 0.9685792594943431\n",
      "====================\n",
      "single heavy\n",
      "f1 0.7089969350855303\n",
      "mcc 0.6818109899278485\n",
      "ap 0.7876350150463332\n",
      "roc 0.9681252743675688\n",
      "====================\n",
      "paired light\n",
      "f1 0.6468729436018179\n",
      "mcc 0.638525809029712\n",
      "ap 0.7529076595919341\n",
      "roc 0.9685747184477042\n",
      "====================\n",
      "single light\n",
      "f1 0.5913634580170368\n",
      "mcc 0.5777079510400438\n",
      "ap 0.6827285552637917\n",
      "roc 0.9579505977343682\n"
     ]
    }
   ],
   "source": [
    "paired_chain[\"IMGT_bis\"] = paired_chain[\"IMGT\"].str.replace(r'[a-zA-Z]$', '', regex=True).astype(int)\n",
    "f1_list = []\n",
    "mcc_list = []\n",
    "ap_list = []\n",
    "roc_list = []\n",
    "for _, df_pdb in paired_chain.query(\"chain_type=='heavy'\").groupby(\"pdb\"):\n",
    "    if len(set(df_pdb[\"labels\"].unique()))==1:\n",
    "        continue\n",
    "    f1_list.append(get_f1_scores(df_pdb, column=\"prediction\", threshold1=0.5, threshold2=0.5))\n",
    "    mcc_list.append(get_mcc_scores(df_pdb, column=\"prediction\", threshold1=0.5, threshold2=0.5))\n",
    "    ap_list.append(get_ap_scores(df_pdb, column=\"prediction\"))\n",
    "    roc_list.append(get_roc_scores(df_pdb, column=\"prediction\"))\n",
    "print(\"paired heavy\")\n",
    "for name,each in zip([\"f1\",\"mcc\",\"ap\",\"roc\"],[f1_list,mcc_list,ap_list, roc_list]):\n",
    "    print(name,np.mean(each))\n",
    "print(\"=\"*20)\n",
    "heavy[\"IMGT_bis\"] = heavy[\"IMGT\"].str.replace(r'[a-zA-Z]$', '', regex=True).astype(int)\n",
    "f1_list = []\n",
    "mcc_list = []\n",
    "ap_list = []\n",
    "roc_list = []\n",
    "for _, df_pdb in heavy.query(\"chain_type=='heavy'\").groupby(\"pdb\"):\n",
    "    if len(set(df_pdb[\"labels\"].unique()))==1:\n",
    "        continue\n",
    "    f1_list.append(get_f1_scores(df_pdb, column=\"prediction\", threshold1=0.5, threshold2=0.5))\n",
    "    mcc_list.append(get_mcc_scores(df_pdb, column=\"prediction\", threshold1=0.5, threshold2=0.5))\n",
    "    ap_list.append(get_ap_scores(df_pdb, column=\"prediction\"))\n",
    "    roc_list.append(get_roc_scores(df_pdb, column=\"prediction\"))\n",
    "print(\"single heavy\")\n",
    "for name,each in zip([\"f1\",\"mcc\",\"ap\",\"roc\"],[f1_list,mcc_list,ap_list, roc_list]):\n",
    "    print(name,np.mean(each))\n",
    "print(\"=\"*20)\n",
    "paired_chain[\"IMGT_bis\"] = paired_chain[\"IMGT\"].str.replace(r'[a-zA-Z]$', '', regex=True).astype(int)\n",
    "f1_list = []\n",
    "mcc_list = []\n",
    "ap_list = []\n",
    "roc_list = []\n",
    "for _, df_pdb in paired_chain.query(\"chain_type=='light'\").groupby(\"pdb\"):\n",
    "    if len(set(df_pdb[\"labels\"].unique()))==1:\n",
    "        continue\n",
    "    f1_list.append(get_f1_scores(df_pdb, column=\"prediction\", threshold1=0.5, threshold2=0.5))\n",
    "    mcc_list.append(get_mcc_scores(df_pdb, column=\"prediction\", threshold1=0.5, threshold2=0.5))\n",
    "    ap_list.append(get_ap_scores(df_pdb, column=\"prediction\"))\n",
    "    roc_list.append(get_roc_scores(df_pdb, column=\"prediction\"))\n",
    "print(\"paired light\")\n",
    "for name,each in zip([\"f1\",\"mcc\",\"ap\",\"roc\"],[f1_list,mcc_list,ap_list, roc_list]):\n",
    "    print(name,np.mean(each))\n",
    "print(\"=\"*20)\n",
    "\n",
    "light[\"IMGT_bis\"] = light[\"IMGT\"].str.replace(r'[a-zA-Z]$', '', regex=True).astype(int)\n",
    "f1_list = []\n",
    "mcc_list = []\n",
    "ap_list = []\n",
    "roc_list = []\n",
    "for _, df_pdb in light.query(\"chain_type=='light'\").groupby(\"pdb\"):\n",
    "    if len(set(df_pdb[\"labels\"].unique()))==1:\n",
    "        continue\n",
    "    f1_list.append(get_f1_scores(df_pdb, column=\"prediction\", threshold1=0.5, threshold2=0.5))\n",
    "    mcc_list.append(get_mcc_scores(df_pdb, column=\"prediction\", threshold1=0.5, threshold2=0.5))\n",
    "    ap_list.append(get_ap_scores(df_pdb, column=\"prediction\"))\n",
    "    roc_list.append(get_roc_scores(df_pdb, column=\"prediction\"))\n",
    "print(\"single light\")\n",
    "for name,each in zip([\"f1\",\"mcc\",\"ap\",\"roc\"],[f1_list,mcc_list,ap_list, roc_list]):\n",
    "    print(name,np.mean(each))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pecan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "paired_chain=pd.read_csv(\"/home/athenes/Paraplume/benchmark/pecan/250526/lr-0.00005_dr-0.4,0.4,0.4_mk-0.4_bs-16_dim1-2000,1000,500_alphas-4,5,6_pen-0.00001_weight_1_emb_all_seed_1/prediction_test_set.csv\")\n",
    "heavy=pd.read_csv(\"/home/athenes/Paraplume/benchmark/pecan/250526/lr-0.00005_dr-0.4,0.4,0.4_mk-0.4_bs-16_dim1-2000,1000,500_alphas-4,5,6_pen-0.00001_weight_1_emb_all_seed_1/prediction_test_set_heavy.csv\")\n",
    "light=pd.read_csv(\"/home/athenes/Paraplume/benchmark/pecan/250526/lr-0.00005_dr-0.4,0.4,0.4_mk-0.4_bs-16_dim1-2000,1000,500_alphas-4,5,6_pen-0.00001_weight_1_emb_all_seed_1/prediction_test_set_light.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paired heavy\n",
      "f1 0.6898727252317213\n",
      "mcc 0.6661756816975023\n",
      "ap 0.7710970789241476\n",
      "roc 0.966392968071185\n",
      "====================\n",
      "single heavy\n",
      "f1 0.6819616326609673\n",
      "mcc 0.6582749359081305\n",
      "ap 0.7655074436336462\n",
      "roc 0.9654268308453322\n",
      "====================\n",
      "paired light\n",
      "f1 0.6172233862614466\n",
      "mcc 0.6074586715640241\n",
      "ap 0.7485541752744719\n",
      "roc 0.9668687956145908\n",
      "====================\n",
      "single light\n",
      "f1 0.5335902854756335\n",
      "mcc 0.5186410189523603\n",
      "ap 0.6713787392307432\n",
      "roc 0.9530561883726795\n"
     ]
    }
   ],
   "source": [
    "paired_chain[\"IMGT_bis\"] = paired_chain[\"IMGT\"].str.replace(r'[a-zA-Z]$', '', regex=True).astype(int)\n",
    "f1_list = []\n",
    "mcc_list = []\n",
    "ap_list = []\n",
    "roc_list = []\n",
    "for _, df_pdb in paired_chain.query(\"chain_type=='heavy'\").groupby(\"pdb\"):\n",
    "    if len(set(df_pdb[\"labels\"].unique()))==1:\n",
    "        continue\n",
    "    f1_list.append(get_f1_scores(df_pdb, column=\"prediction\", threshold1=0.5, threshold2=0.5))\n",
    "    mcc_list.append(get_mcc_scores(df_pdb, column=\"prediction\", threshold1=0.5, threshold2=0.5))\n",
    "    ap_list.append(get_ap_scores(df_pdb, column=\"prediction\"))\n",
    "    roc_list.append(get_roc_scores(df_pdb, column=\"prediction\"))\n",
    "print(\"paired heavy\")\n",
    "for name,each in zip([\"f1\",\"mcc\",\"ap\",\"roc\"],[f1_list,mcc_list,ap_list, roc_list]):\n",
    "    print(name,np.mean(each))\n",
    "print(\"=\"*20)\n",
    "heavy[\"IMGT_bis\"] = heavy[\"IMGT\"].str.replace(r'[a-zA-Z]$', '', regex=True).astype(int)\n",
    "f1_list = []\n",
    "mcc_list = []\n",
    "ap_list = []\n",
    "roc_list = []\n",
    "for _, df_pdb in heavy.query(\"chain_type=='heavy'\").groupby(\"pdb\"):\n",
    "    if len(set(df_pdb[\"labels\"].unique()))==1:\n",
    "        continue\n",
    "    f1_list.append(get_f1_scores(df_pdb, column=\"prediction\", threshold1=0.5, threshold2=0.5))\n",
    "    mcc_list.append(get_mcc_scores(df_pdb, column=\"prediction\", threshold1=0.5, threshold2=0.5))\n",
    "    ap_list.append(get_ap_scores(df_pdb, column=\"prediction\"))\n",
    "    roc_list.append(get_roc_scores(df_pdb, column=\"prediction\"))\n",
    "print(\"single heavy\")\n",
    "for name,each in zip([\"f1\",\"mcc\",\"ap\",\"roc\"],[f1_list,mcc_list,ap_list, roc_list]):\n",
    "    print(name,np.mean(each))\n",
    "print(\"=\"*20)\n",
    "paired_chain[\"IMGT_bis\"] = paired_chain[\"IMGT\"].str.replace(r'[a-zA-Z]$', '', regex=True).astype(int)\n",
    "f1_list = []\n",
    "mcc_list = []\n",
    "ap_list = []\n",
    "roc_list = []\n",
    "for _, df_pdb in paired_chain.query(\"chain_type=='light'\").groupby(\"pdb\"):\n",
    "    if len(set(df_pdb[\"labels\"].unique()))==1:\n",
    "        continue\n",
    "    f1_list.append(get_f1_scores(df_pdb, column=\"prediction\", threshold1=0.5, threshold2=0.5))\n",
    "    mcc_list.append(get_mcc_scores(df_pdb, column=\"prediction\", threshold1=0.5, threshold2=0.5))\n",
    "    ap_list.append(get_ap_scores(df_pdb, column=\"prediction\"))\n",
    "    roc_list.append(get_roc_scores(df_pdb, column=\"prediction\"))\n",
    "print(\"paired light\")\n",
    "for name,each in zip([\"f1\",\"mcc\",\"ap\",\"roc\"],[f1_list,mcc_list,ap_list, roc_list]):\n",
    "    print(name,np.mean(each))\n",
    "print(\"=\"*20)\n",
    "\n",
    "light[\"IMGT_bis\"] = light[\"IMGT\"].str.replace(r'[a-zA-Z]$', '', regex=True).astype(int)\n",
    "f1_list = []\n",
    "mcc_list = []\n",
    "ap_list = []\n",
    "roc_list = []\n",
    "for _, df_pdb in light.query(\"chain_type=='light'\").groupby(\"pdb\"):\n",
    "    if len(set(df_pdb[\"labels\"].unique()))==1:\n",
    "        continue\n",
    "    f1_list.append(get_f1_scores(df_pdb, column=\"prediction\", threshold1=0.5, threshold2=0.5))\n",
    "    mcc_list.append(get_mcc_scores(df_pdb, column=\"prediction\", threshold1=0.5, threshold2=0.5))\n",
    "    ap_list.append(get_ap_scores(df_pdb, column=\"prediction\"))\n",
    "    roc_list.append(get_roc_scores(df_pdb, column=\"prediction\"))\n",
    "print(\"single light\")\n",
    "for name,each in zip([\"f1\",\"mcc\",\"ap\",\"roc\"],[f1_list,mcc_list,ap_list, roc_list]):\n",
    "    print(name,np.mean(each))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "paired_chain=pd.read_csv(\"/home/athenes/Paraplume/benchmark/mipe/250526/lr-0.00005_dr-0.4,0.4,0.4_mk-0.4_bs-16_dim1-2000,1000,500_alphas-4,5,6_pen-0.00001_weight_1_emb_all_seed_1/0/prediction_test_set.csv\")\n",
    "heavy=pd.read_csv(\"/home/athenes/Paraplume/benchmark/mipe/250526/lr-0.00005_dr-0.4,0.4,0.4_mk-0.4_bs-16_dim1-2000,1000,500_alphas-4,5,6_pen-0.00001_weight_1_emb_all_seed_1/0/prediction_test_set_heavy.csv\")\n",
    "light=pd.read_csv(\"/home/athenes/Paraplume/benchmark/mipe/250526/lr-0.00005_dr-0.4,0.4,0.4_mk-0.4_bs-16_dim1-2000,1000,500_alphas-4,5,6_pen-0.00001_weight_1_emb_all_seed_1/0/prediction_test_set_light.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paired heavy\n",
      "f1 0.6447108844108996\n",
      "mcc 0.6234009189046661\n",
      "ap 0.7260233033509083\n",
      "roc 0.958768212298608\n",
      "====================\n",
      "single heavy\n",
      "f1 0.6075360275879612\n",
      "mcc 0.5916669018547479\n",
      "ap 0.7251036623963572\n",
      "roc 0.9588217204222435\n",
      "====================\n",
      "paired light\n",
      "f1 0.644185399268788\n",
      "mcc 0.638152382722701\n",
      "ap 0.7580078334331026\n",
      "roc 0.9718203419120744\n",
      "====================\n",
      "single light\n",
      "f1 0.5682453424487163\n",
      "mcc 0.5670303844833805\n",
      "ap 0.73599696588962\n",
      "roc 0.9645158935201342\n"
     ]
    }
   ],
   "source": [
    "paired_chain[\"IMGT_bis\"] = paired_chain[\"IMGT\"].str.replace(r'[a-zA-Z]$', '', regex=True).astype(int)\n",
    "f1_list = []\n",
    "mcc_list = []\n",
    "ap_list = []\n",
    "roc_list = []\n",
    "for _, df_pdb in paired_chain.query(\"chain_type=='heavy'\").groupby(\"pdb\"):\n",
    "    if len(set(df_pdb[\"labels\"].unique()))==1:\n",
    "        continue\n",
    "    f1_list.append(get_f1_scores(df_pdb, column=\"prediction\", threshold1=0.5, threshold2=0.5))\n",
    "    mcc_list.append(get_mcc_scores(df_pdb, column=\"prediction\", threshold1=0.5, threshold2=0.5))\n",
    "    ap_list.append(get_ap_scores(df_pdb, column=\"prediction\"))\n",
    "    roc_list.append(get_roc_scores(df_pdb, column=\"prediction\"))\n",
    "print(\"paired heavy\")\n",
    "for name,each in zip([\"f1\",\"mcc\",\"ap\",\"roc\"],[f1_list,mcc_list,ap_list, roc_list]):\n",
    "    print(name,np.mean(each))\n",
    "print(\"=\"*20)\n",
    "heavy[\"IMGT_bis\"] = heavy[\"IMGT\"].str.replace(r'[a-zA-Z]$', '', regex=True).astype(int)\n",
    "f1_list = []\n",
    "mcc_list = []\n",
    "ap_list = []\n",
    "roc_list = []\n",
    "for _, df_pdb in heavy.query(\"chain_type=='heavy'\").groupby(\"pdb\"):\n",
    "    if len(set(df_pdb[\"labels\"].unique()))==1:\n",
    "        continue\n",
    "    f1_list.append(get_f1_scores(df_pdb, column=\"prediction\", threshold1=0.5, threshold2=0.5))\n",
    "    mcc_list.append(get_mcc_scores(df_pdb, column=\"prediction\", threshold1=0.5, threshold2=0.5))\n",
    "    ap_list.append(get_ap_scores(df_pdb, column=\"prediction\"))\n",
    "    roc_list.append(get_roc_scores(df_pdb, column=\"prediction\"))\n",
    "print(\"single heavy\")\n",
    "for name,each in zip([\"f1\",\"mcc\",\"ap\",\"roc\"],[f1_list,mcc_list,ap_list, roc_list]):\n",
    "    print(name,np.mean(each))\n",
    "print(\"=\"*20)\n",
    "paired_chain[\"IMGT_bis\"] = paired_chain[\"IMGT\"].str.replace(r'[a-zA-Z]$', '', regex=True).astype(int)\n",
    "f1_list = []\n",
    "mcc_list = []\n",
    "ap_list = []\n",
    "roc_list = []\n",
    "for _, df_pdb in paired_chain.query(\"chain_type=='light'\").groupby(\"pdb\"):\n",
    "    if len(set(df_pdb[\"labels\"].unique()))==1:\n",
    "        continue\n",
    "    f1_list.append(get_f1_scores(df_pdb, column=\"prediction\", threshold1=0.5, threshold2=0.5))\n",
    "    mcc_list.append(get_mcc_scores(df_pdb, column=\"prediction\", threshold1=0.5, threshold2=0.5))\n",
    "    ap_list.append(get_ap_scores(df_pdb, column=\"prediction\"))\n",
    "    roc_list.append(get_roc_scores(df_pdb, column=\"prediction\"))\n",
    "print(\"paired light\")\n",
    "for name,each in zip([\"f1\",\"mcc\",\"ap\",\"roc\"],[f1_list,mcc_list,ap_list, roc_list]):\n",
    "    print(name,np.mean(each))\n",
    "print(\"=\"*20)\n",
    "\n",
    "light[\"IMGT_bis\"] = light[\"IMGT\"].str.replace(r'[a-zA-Z]$', '', regex=True).astype(int)\n",
    "f1_list = []\n",
    "mcc_list = []\n",
    "ap_list = []\n",
    "roc_list = []\n",
    "for _, df_pdb in light.query(\"chain_type=='light'\").groupby(\"pdb\"):\n",
    "    if len(set(df_pdb[\"labels\"].unique()))==1:\n",
    "        continue\n",
    "    f1_list.append(get_f1_scores(df_pdb, column=\"prediction\", threshold1=0.5, threshold2=0.5))\n",
    "    mcc_list.append(get_mcc_scores(df_pdb, column=\"prediction\", threshold1=0.5, threshold2=0.5))\n",
    "    ap_list.append(get_ap_scores(df_pdb, column=\"prediction\"))\n",
    "    roc_list.append(get_roc_scores(df_pdb, column=\"prediction\"))\n",
    "print(\"single light\")\n",
    "for name,each in zip([\"f1\",\"mcc\",\"ap\",\"roc\"],[f1_list,mcc_list,ap_list, roc_list]):\n",
    "    print(name,np.mean(each))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
